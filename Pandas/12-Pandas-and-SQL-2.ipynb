{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and SQL - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the NRI point  data\n",
    "Below, we read the csv files into a Pandas dataFrame as we have in the past - with a few exceptions.\n",
    "\n",
    "Pandas, like MS Access, will infer the data type from the values it's importing. However, we have some numeric fields that need to be imported as strings: the `recordid`, `fips`, `hydro`, `mhydro`, and `mlra` fields. To do this, we create a dictionary of field names and the field types we want to override. Any fields left of this list will get the default data types.\n",
    "\n",
    "We will also set the recordid as the index for the dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataType dictionary\n",
    "dtypeDict = {'recordid':'str',\n",
    "             'fips':'str',\n",
    "             'hydro':'str',\n",
    "             'mhydro':'str',\n",
    "             'mlra':'str'\n",
    "            }\n",
    "\n",
    "#Read in the data\n",
    "dfPoint = pd.read_csv('../Data/nc_point.csv',\n",
    "                      index_col='recordid',\n",
    "                      dtype=dtypeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data types\n",
    "dfPoint.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a quick look \n",
    "dfPoint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now it's your turn. Import the nc_trend.csv file. Set the following columns to be strings: `recordid`,`yr`,`landuse`,`broad`. (Others columns with nominal data should be strings, but this will suffice...). Also, as above, set the `recordid` column to be the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypeDict = {'recordid':'str',\n",
    "             'yr':'str',\n",
    "             'landuse':'str',\n",
    "             'broad':'str'\n",
    "            }\n",
    "\n",
    "dfTrend = pd.read_csv(\"../Data/nc_trend.csv\", dtype=dtypeDict, index_col='recordid')\n",
    "dfTrend.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we are read to analyse the data (and learn how Pandas does it...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First another example of an aggregate function: Lets count the number of samples and total area of each location within each county using the `dfPoint` dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the grouping object\n",
    "grpCounty = dfPoint.groupby('fips')\n",
    "type(grpCounty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With this DataFrameGroupBy object we can apply different aggregate functions.\n",
    "dfX = grpCounty['fips'].agg('count')\n",
    "dfX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum up the xfact values and muliply by 10\n",
    "dfX = grpCounty['xfact'].agg('sum')\n",
    "dfX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or we can combine the aggregating functions into a single \n",
    "# command using a dictionary to define how we want to aggregate\n",
    "\n",
    "#Create a dictionary of field names: aggregating functions\n",
    "grpFunctions = {'fips':['count'],'xfact':['sum']}\n",
    "\n",
    "#Apply them all at once\n",
    "dfX = grpCounty['xfact'].agg(grpFunctions)\n",
    "dfX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data\n",
    "Pandas can pivot data too. Let's pivot our `dfTrend` table so that it moves the year values into columns and presents the value in the `broad` column (for each year). This is done with the Pandas `pivot` function. The `columns` parameter is where we specify the column on which we want to pivot our data, and the `values` parameter is where we specify the column from which we take the values,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfTrend.pivot(columns='yr',values='broad')\n",
    "dfX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the broad codes dataFrame\n",
    "dataDict = {'codes':['1','2','3','4','5','6','7','8','9','10','11','12'],\n",
    "            'description':['Cropland_cultivated',\n",
    "                      'Cropland_noncultivated',\n",
    "                      'Pastureland',\n",
    "                      'Rangeland',\n",
    "                      'Forest land',\n",
    "                      'Other rural land',\n",
    "                      'Urban and built-up land',\n",
    "                      'Rural transportation',\n",
    "                      'Small water areas',\n",
    "                      'Census water',\n",
    "                      'Federal land',\n",
    "                      'Conservation reserve program (CRP) land']}\n",
    "dfBroadCodes = pd.DataFrame(dataDict,dtype='str')\n",
    "dfBroadCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join to the dfX dataFrame\n",
    "dfY = pd.merge(left=dfTrend,\n",
    "               right=dfBroadCodes,\n",
    "               how='outer',\n",
    "               left_on='broad',\n",
    "               right_on='codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-pivot\n",
    "dfTrend.pivot(columns='yr',values='broad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
