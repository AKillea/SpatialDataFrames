{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis with GeoPandas\n",
    "In this exercise, we use GeoPandas to identify census tracts within 1km of EV charging locations in a region in NC. \n",
    "* [Input/Output](https://geopandas.org/io.html) Reading a CSV file into a GeoPandas geodataframe\n",
    "* [Index and Selecting data](https://geopandas.org/indexing.html): Subsetting records\n",
    "* [Managing Projections](https://geopandas.org/projections.html): Projecting a geodataframe\n",
    "* [Geometric manipulations](https://geopandas.org/geometric_manipulations.html): Buffering points\n",
    "* [Set operations](https://geopandas.org/set_operations.html): intersect\n",
    "* [Aggregrating data](https://geopandas.org/aggregation_with_dissolve.html): Dissolving features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Fetching and Exploring the Data\n",
    "Here we'll gather and explore the data we'll be using in our analysis. This includes two datasets. First is the list of EV Charging locations, stored as a CSV file in our data folder. This dataset has coordinate columns that we'll use to construct points and convert into a geodataframe.\n",
    "\n",
    "The second dataset is comprised of 2010 Census BlockGroup data for all of North Carolina. We'll fetch these data from an on line resource using a web service. We'll revisit how web services later; for now, we'll use this process to fetch data for three counties: Durham, Wake, and Orange. \n",
    "\n",
    "For each dataset, we'll get the data into geodataframe format and then explore the data in various ways. Then we'll move to Part 2 where we analyse the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ♦Step 1. Import packages needed in the analysis\n",
    ">**Knowledge check**:<br>\n",
    "→ Can you explain what role each package imported might do in our analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ♦Step 2. Create a geodataframe from a CSV file\n",
    "As done in a previous notebook, we want to:\n",
    "* Import a CSV file containing coordinate columns into a Pandas dataframe,\n",
    "* Create a collection of Shapely points from the coordinate fields, and \n",
    "* Create a geodataframe from the components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in charging stations CSV, convert to geodataframe\n",
    "df = pd.read_csv('./data/NC_Charging_Stations.csv')\n",
    "geom = [Point(xy) for xy in zip(df['Longitude'],df['Latitude'])]\n",
    "gdf_stations_all = gpd.GeoDataFrame(df,geometry=geom,crs=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ♦Step 3. Explore the data in geodataframe\n",
    "Have a quick look at the contents imported. Things to check include:\n",
    "* How many rows and columns were imported\n",
    "* The names, data types, and number of non-null values in each column\n",
    "* Summary statistics of numeric columns, if applicable\n",
    "* Correlations among column values, if applicable\n",
    "* Spatial plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the data\n",
    "gdf_stations_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "gdf_stations_all.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### ►TASK: Import the USGS gage points for NC: `./data/gages.csv`\n",
    "> * Convert data to a geodataframe: `gdf_gages`\n",
    "> * Explore the data\n",
    "> * Plot the gage sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ♦Step 4. Import NC Census Block Group features via NC OneMap's web service\n",
    "_We will explore web services a bit later, but we'll use the code below to acquire polygon data of census block groups for Durham, Wake, and Orange counties from an NC OneMap Web Service. Once imported, we'll merge these geodataframes together and use them in our subsequet analyses._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, to simplify matters, I've created a Python function to fetch data for a specific county given its FIPS code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to read NCOneMap feature services into a geodataframe\n",
    "def getBlockGroupData(FIPS):\n",
    "    #Construct the url from the function arguments\n",
    "    url=f'https://services.nconemap.gov/secure/rest/services/NC1Map_Census/FeatureServer/8/query?' + \\\n",
    "        f\"where=GEOID10+LIKE+'{FIPS}%'&outFields=GEOID10,TOTAL_POP&f=geojson\"\n",
    "    \n",
    "    #Create a geodataframe from the URL\n",
    "    gdf = gpd.read_file(url)\n",
    "    \n",
    "    #Return the geodataframe\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we apply that function for the three counties we want to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch census block groups for Durham, Orange, and Wake counties using the above function\n",
    "gdf_DurmBlkGroups = getBlockGroupData(37063)\n",
    "gdf_WakeBlkGroups = getBlockGroupData(37183)\n",
    "gdf_OrangeBlkGroups = getBlockGroupData(37135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Challenge: See if you can fetch Chatham county block groups (FIPS = 37037)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Challenge: See if you can fetch Chatham county block groups (FIPS = 37037)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explore** the data...\n",
    " * What is its coordinate reference system?\n",
    " * What columns are included?\n",
    " * What does the first record look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the Durham block group geodataframe's coordinate reference system\n",
    "gdf_DurmBlkGroups.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the Durham block group geodataframe's columns...\n",
    "gdf_DurmBlkGroups.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine a sample record from the geodataframe\n",
    "gdf_DurmBlkGroups.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualize** the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Durhham's population\n",
    "gdf_DurmBlkGroups.plot('TOTAL_POP',cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the block groups for all three counties\n",
    "thePlot = gdf_DurmBlkGroups.plot(color='blue')\n",
    "gdf_WakeBlkGroups.plot(ax=thePlot,color='red')\n",
    "gdf_OrangeBlkGroups.plot(ax=thePlot,color='lightblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The analysis\n",
    "Now that we've obtained a few datasets and got them into geodataframes, we'll perform some analysis. These include:\n",
    "* Subsetting the EV charging stations for those in specific cities.\n",
    "* Identifying the census blocks surrounding each EV station, within a distance of 1km\n",
    " * To do this, we'll merge the Durham, Wake, and Orange Co block data selected above\n",
    " * Then we'll buffer our selected EV station points a distance of 1km\n",
    " * And finally, we'll select blocks that intersect the EV station buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 1: Subset the EV Station points based on attribute values\n",
    "Doc: https://geopandas.org/indexing.html\n",
    "\n",
    "Subsetting features in a geodataframe uses the same methods as subsetting recordsin a Pandas dataframe. Here we'll run through an example by subsetting EV stations found oly within Durham, Raleigh, and Chapel Hill. \n",
    "\n",
    "* **Step 1** Examine unique values in the `City` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the unique values in the City column\n",
    "gdf_stations_all['City'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 2** Subset records for those where the City is \"Durham\", \"Raleigh\", or \"Chapel Hill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset records where the City is \"Durham\", \"Raleigh\", or \"Chapel Hill\"\n",
    "gdf_stations = gdf_stations_all.query('City in (\"Durham\",\"Raleigh\",\"Chapel Hill\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 3** Explore the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "gdf_stations.plot(\"City\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them with a base map\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "gdf_stations.to_crs(3857).plot(ax=ax, column=\"City\")\n",
    "ctx.add_basemap(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2. Merge the 3 county block group geodataframes into one\n",
    "Doc: https://geopandas.org/mergingdata.html\n",
    "1. Check that all data have the same crs\n",
    "1. Optionally, add a field to identify the source geodataframe\n",
    "1. Apply the `append()` function\n",
    "1. Check/explore the result\n",
    "\n",
    "We'll start by appending the Wake Co. dataset to the Durham Co. one. Then you will append the Orange Co. dataframe to that product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 1** Check that the two files share the same coordinate reference system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the crs of the two geodataframes\n",
    "gdf_DurmBlkGroups.crs == gdf_WakeBlkGroups.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 2** Add an identifying column to the source geodataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a field to each input, setting values to identify the source dataset\n",
    "gdf_DurmBlkGroups['County'] = 'Durham'\n",
    "gdf_WakeBlkGroups['County'] = 'Wake'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 3** Append one dataframe to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the Wake Co features to the Durham Co features,\n",
    "gdf_BlkGrp_step1 = gdf_DurmBlkGroups.append(gdf_WakeBlkGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 4** Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see that the total rows in the merged gdf match the sum of the two component gdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the result\n",
    "gdf_BlkGrp_step1.plot('County');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TASK:\n",
    "_Now you try to append the Orange Co blockgroup features to the `gdf_BlkGrp_step` geodataframe we just created._\n",
    "\n",
    "**Remember to:**\n",
    "* check that the coordinate refernce systems are the same, and \n",
    "* add a new column to the `gdf_OrangeBlkGroups`, setting its value to the County name.\n",
    " \n",
    "→ Save the result as `gdf_BlkGrps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the coordinate refernce systems are the same\n",
    "gdf_BlkGrp_step1.crs == gdf_OrangeBlkGroups.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the county field\n",
    "gdf_OrangeBlkGroups['County'] = 'Orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the geodataframes\n",
    "gdf_BlkGrp = gdf_BlkGrp_step1.append(gdf_OrangeBlkGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the output\n",
    "gdf_BlkGrp.plot('County');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 3: Dissolve block features to the tract level\n",
    "We have Social Vulnerability Data to examine in our analysis, but these data are at the Tract, not BlockGroup level. Thus, to join these attributes to our geodataframe, we'll need to aggregate our blockgroups to the tract level. Fortunately, the `GEOID10` attribute is structured such that the census tract is just the first 11 characters. So we will create a new column holding these first 11 characters, and then we'll dissolve our blockgroup features sharing the same tract ID to single features.\n",
    "\n",
    "Doc: https://geopandas.org/aggregation_with_dissolve.html\n",
    "* First, create a new column listing tract IDs (the first 11 digits of the GEOID10)\n",
    "* Dissolve the features on this attribute, computing aggregate sum of the TOTAL_POP field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 1** Create the Tract column from the GEOID10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Tract column\n",
    "gdf_BlkGrp['TRACT']=gdf_BlkGrp['GEOID10'].str[:11]\n",
    "gdf_BlkGrp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 2** Dissolve features on the Tract column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dissolve features on tract, computing summed population\n",
    "gdf_Tract = gdf_BlkGrp.dissolve('TRACT',aggfunc={'TOTAL_POP':'sum','County':'first'})\n",
    "gdf_Tract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "gdf_Tract.plot('TOTAL_POP',cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 4: Import the Social Vulnerability Data and join with the Tract features\n",
    "Now that we have the data at the tract level, we can join the Social Vulnerability Index data, stored in a CSV file (`./data/NC_SVI_2018.csv`).\n",
    "\n",
    "Doc: https://geopandas.org/mergingdata.html#attribute-joins\n",
    "* Import the SVI data as a Pandas dataframe\n",
    "* Append records from the SVI dataframe to the Tracts geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 1** Import and explore the SVI data into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and explore the SVI data\n",
    "df_SVI = pd.read_csv('./data/NC_SVI_2018.csv',dtype={'FIPS':'str',})\n",
    "df_SVI.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Challenge**:<br>→ _Modify the `read_csv()` command above so that 'ST' and 'STCNTY' are also imported as strings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of the SVI values\n",
    "df_SVI['SVI'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color='red'> Whoops!!! </h3></font>\n",
    "Values should be between 0 and 1, but we see in the histogram that a few value are down near -1000. Turns out a few records have SVI values of -999. We need to remove those records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of values greater than or equal to zero\n",
    "valid_mask = df_SVI['SVI'] >= 0\n",
    "#Apply that mask\n",
    "df_SVI_fixed = df_SVI.loc[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the histogram again\n",
    "df_SVI_fixed['SVI'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Phew! Exploring the data payed off!_\n",
    "\n",
    "* **Step 2** Append the dataframe to the tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at the merge command syntax\n",
    "gdf_Tract.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_Tract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the SVI data to the tract features\n",
    "gdf_Tract_joined = gdf_Tract.merge(df_SVI_fixed,\n",
    "                                   left_on='TRACT', #\"Join to\" field in the traft features \n",
    "                                   right_on='FIPS', #\"Join on\" field in the SVI dataframe\n",
    "                                   how='left')      #Keep all tract features, even if they are missing SVI\n",
    "#Examine the output\n",
    "gdf_Tract_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the output\n",
    "gdf_Tract_joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the output\n",
    "gdf_Tract_joined.plot('SVI',figsize=(7,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Looks like we have some features missing SVI data. Let's examine those more closely._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of null SVI values\n",
    "gdf_Tract_joined['SVI'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the mask\n",
    "gdf_Tract_joined.loc[gdf_Tract_joined['SVI'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We can either assign a value to these missing values or leave them as no data. We'll just leave them blank for now..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Step 5: Compute Population Density for Each Tract\n",
    "Our combined dataframes have a field indicating the total population in each block group. We want to compute population density from this and from the area of each tract. We don't yet have an area field in our dataframe, but we can compute that from our spatial features. But before we can do this, we need to transform our data into a projected coordinate system. So... the steps for this analysis include:\n",
    "* Project the dataframe from WGS84 to UTM Zone 17N\n",
    "* Compute a new `Area_km2` column in our dataframe\n",
    "* Compute a new `PopDens` column in our dataframe by dividing `TOTAL_POP` by `Area_km` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project the data to UTM Zone 17N (EPSG 32617)\n",
    "gdf_Tract_utm = gdf_Tract_joined.to_crs(32617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute a new column of geometry area (in sq km)\n",
    "gdf_Tract_utm['Area_km2'] = gdf_Tract_utm['geometry'].area / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute a new column of population density\n",
    "gdf_Tract_utm['PopDens'] = gdf_Tract_utm['TOTAL_POP'] / gdf_Tract_utm['Area_km2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of areas\n",
    "gdf_Tract_utm['PopDens'].hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a map of log tranformed population density\n",
    "gdf_Tract_utm.plot('PopDens',figsize=(10,8),cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transform the pop_dens data\n",
    "import numpy as np\n",
    "gdf_Tract_utm['PD_log'] = np.log(gdf_Tract_utm['PopDens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the log-transformed distribution of areas\n",
    "gdf_Tract_utm['PD_log'].hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a map of log tranformed population density\n",
    "gdf_Tract_utm.plot('PD_log',figsize=(10,8),cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_Tract_utm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: Subset EV stations spatially. \n",
    "Doc: https://geopandas.org/set_operations.html\n",
    "Previously, we subset EV stations by an attribute (City). Here we'll see how we can instead select features spatially. We do this with GeoPanda's Overlay operations.\n",
    "\n",
    "To spatially select features:\n",
    "* Ensure both datasets share the same coordinate reference system; transform if needed\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot points on tracts\n",
    "ax = gdf_Tract_utm.plot(figsize=(12,6),alpha=0.3)\n",
    "gdf_stations_utm.plot(column='City',ax=ax,markersize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get both datasets into the same crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure both datasets share the same crs\n",
    "print(gdf_stations_all.crs, gdf_Tract_utm.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project one dataset to match the other\n",
    "gdf_stations_all_utm = gdf_stations_all.to_crs(gdf_Tract_utm.crs)\n",
    "print(gdf_stations_all_utm.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select EV stations that intersect the county features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show info on the overlay function\n",
    "gdf_stations_select = gpd.overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersect the two dataframes\n",
    "gdf_stations_select = gpd.overlay(\n",
    "    df1=gdf_stations_all_utm,\n",
    "    df2=gdf_Tract_utm,\n",
    "    how='intersection'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stations_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "ax = gdf_Tract_utm.plot(color='lightgrey',edgecolor='grey',alpha=0.4,figsize=(12,12))\n",
    "gdf_stations_select.plot(ax=ax,column='City',markersize=45,edgecolor='white');\n",
    "ctx.add_basemap(ax, crs=gdf_Tract_utm.crs,source=ctx.providers.CartoDB.Voyager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: Spatial Join\n",
    "Doc: https://geopandas.org/mergingdata.html#spatial-joins\n",
    "\n",
    "Now that we have a proper susbset of EV stations, let's examine the block groups in which each EV stations falls. We do this with a Spatial Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get syntax of sjoin function\n",
    "gpd.sjoin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buffer the selected sites\n",
    "gdf_stations_select['geometry'] = gdf_stations_select.buffer(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the spatial join\n",
    "gdf_JoinedData = gpd.sjoin(\n",
    "    left_df = gdf_stations_select,\n",
    "    right_df = gdf_Tract_utm,\n",
    "    how='inner',\n",
    "    op='intersects',\n",
    "    lsuffix='ev',\n",
    "    rsuffix='census'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_JoinedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_JoinedData[['SVI_right','PopDens_right']].plot(kind='scatter',x='SVI_right',y='PopDens_right',color='City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "ax = gdf_Tract_utm.plot(color='lightgrey',edgecolor='grey',alpha=0.4,figsize=(12,12))\n",
    "gdf_JoinedData.plot(ax=ax,column='SVI_right',markersize='SVI_right',edgecolor='white');\n",
    "ctx.add_basemap(ax, crs=gdf_Tract_utm.crs,source=ctx.providers.CartoDB.Voyager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
